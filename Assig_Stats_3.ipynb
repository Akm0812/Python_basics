{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-x8a42Vo9sh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4XP4yQt5pA-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q.1. Explain the properties of the F-distribution.\n",
        "\n",
        "Answer- The F-distribution is a continuous probability distribution that arises frequently in the analysis of variance (ANOVA) and other statistical tests.\n",
        "\n",
        "Key Properties:\n",
        "Non-Negative: Values are always greater than or equal to zero.\n",
        "\n",
        "Right-Skewed: The distribution is asymmetrical and skewed to the right.\n",
        "\n",
        "Dependent on Degrees of Freedom: The shape of the F-distribution depends on two sets of degrees of freedom:\n",
        "\n",
        "ùëë1: Degrees of freedom for the numerator.\n",
        "\n",
        "ùëë2: Degrees of freedom for the denominator.\n",
        "\n",
        "Ratio of Variances: It is formed by the ratio of two chi-squared distributions, each divided by their respective degrees of freedom.\n",
        "\n",
        "USE----\n",
        "ANOVA (Analysis of Variance): To compare the variances across groups.\n",
        "\n",
        "Regression Analysis: To test the overall significance of a regression model.\n",
        "\n",
        "Comparing Models: To compare the fits of two nested models."
      ],
      "metadata": {
        "id": "Lf3709XUpCAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q.2. In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?\n",
        "\n",
        "Answer-The F-distribution is mainly used in the following types of statistical tests:\n",
        "\n",
        "1. Analysis of Variance (ANOVA)\n",
        "Purpose: To compare the variances between groups to determine if there are any significant differences.\n",
        "\n",
        "Why F-distribution: The F-ratio is the ratio of the variance between groups to the variance within groups, and the F-distribution helps in determining if this ratio is significantly larger than 1.\n",
        "\n",
        "2. Regression Analysis\n",
        "Purpose: To test the overall significance of a regression model and compare the fits of different models.\n",
        "\n",
        "Why F-distribution: The F-test assesses the joint effect of multiple predictors in a regression model by comparing the variance explained by the model to the unexplained variance.\n",
        "\n",
        "3. Comparing Models\n",
        "Purpose: To compare nested models to see if the more complex model significantly improves the fit.\n",
        "\n",
        "Why F-distribution: It evaluates the ratio of variances explained by the full model versus the reduced model, indicating if additional predictors improve the model significantly.\n",
        "\n",
        "Why Appropriate----\n",
        "The F-distribution is perfect for these tests because it deals with ratios of variances and helps in testing the null hypothesis that variances  are equal across different groups or models."
      ],
      "metadata": {
        "id": "n8A03c4cp-q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q.3. What are the key assumptions required for conducting an F-test to compare the variances of two\n",
        "populations?\n",
        "\n",
        "Answer-To conduct an F-test to compare the variances of two populations, you need to ensure several key assumptions are met:\n",
        "\n",
        "Key Assumptions:\n",
        "Independence: The samples must be independently drawn from the populations.\n",
        "\n",
        "Normality: Each population should be normally distributed. This is particularly important for smaller sample sizes.\n",
        "\n",
        "Random Sampling: The samples must be randomly selected from the populations.\n",
        "\n",
        "Equal Sample Size : While not strictly necessary, having equal sample sizes makes the test more robust.\n",
        "\n",
        "Variance Homogeneity (only for two-sample t-tests): This is assumed to hold true for performing the test, meaning the variances of the two populations being compared should ideally be similar."
      ],
      "metadata": {
        "id": "LwOPHFeBqntb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q.4. What is the purpose of ANOVA, and how does it differ from a t-test?\n",
        "\n",
        "Answer - ANOVA (Analysis of Variance) and t-tests are both used to determine if there are significant differences between groups, but they serve different purposes and are used in different contexts.\n",
        "\n",
        "Purpose of ANOVA\n",
        "Compare Multiple Groups: ANOVA is used to compare the means of three or more groups.\n",
        "\n",
        "Assess Variance: It assesses whether the observed variance between groups is significantly greater than the variance within groups.\n",
        "\n",
        "How ANOVA Differs from a t-test\n",
        "Number of Groups:\n",
        "\n",
        "t-test: Compares the means of two groups.\n",
        "\n",
        "ANOVA: Can compare the means of three or more groups.\n",
        "\n",
        "Hypotheses:\n",
        "\n",
        "t-test: Tests if the means of two groups are significantly different.\n",
        "\n",
        "ANOVA: Tests if at least one group mean is significantly different from the others.\n",
        "\n",
        "F-test in ANOVA:\n",
        "\n",
        "ANOVA uses the F-distribution to determine the significance, whereas t-tests use the t-distribution.\n",
        "\n",
        "Post-hoc Testing:\n",
        "\n",
        "If ANOVA shows significant differences, post-hoc tests (like Tukey's HSD) are needed to identify which specific groups differ.\n",
        "\n",
        "Example\n",
        "t-test: Comparing the average test scores between two classes.\n",
        "\n",
        "ANOVA: Comparing the average test scores across multiple classes (Class A, Class B, Class C, etc.)."
      ],
      "metadata": {
        "id": "5fNPpVdnsLIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q.5. Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more\n",
        "than two groups.\n",
        "\n",
        "Answer- When to Use One-Way ANOVA Instead of Multiple t-Tests\n",
        "One-way ANOVA is used when you have three or more groups to compare.\n",
        "\n",
        "Why Use One-Way ANOVA\n",
        "Avoids Increased Type I Error: Conducting multiple t-tests increases the probability of making a Type I error (false positive). ANOVA maintains a single significance level across all comparisons.\n",
        "\n",
        "Comprehensive Analysis: ANOVA assesses all group comparisons simultaneously, providing a more holistic view of the data.\n",
        "\n",
        "Efficiency: One test instead of many simplifies the analysis.\n",
        "\n",
        "Example\n",
        "If you want to compare the average test scores of students from three different classes (Class A, Class B, Class C), a one-way ANOVA would be more appropriate than multiple t-tests to avoid inflated error rates and to get a clearer overall picture."
      ],
      "metadata": {
        "id": "nkIFPUq0svst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q.6. Explain how variance is partitioned in ANOVA into between-group variance and within-group variance.\n",
        "How does this partitioning contribute to the calculation of the F-statistic?\n",
        "\n",
        "Answer- In ANOVA, variance is divided into two main components: between-group variance and within-group variance. Here‚Äôs how it works:\n",
        "\n",
        "Between-Group Variance (SSB)\n",
        "This measures the variance due to the interaction between the different groups. It looks at how much the group means differ from the overall mean.\n",
        "\n",
        "Calculation:\n",
        "\n",
        "Calculate the mean of each group.\n",
        "\n",
        "Find the overall mean of all data points.\n",
        "\n",
        "Sum the squared differences between each group mean and the overall mean, weighted by the number of observations in each group.\n",
        "\n",
        "Within-Group Variance (SSW)\n",
        "This measures the variance within each group. It considers how much individual data points within a group differ from the group mean.\n",
        "\n",
        "Calculation:\n",
        "\n",
        "Calculate the mean of each group.\n",
        "\n",
        "Sum the squared differences between each data point and its respective group mean.\n",
        "\n",
        "Total Variance (SST)\n",
        "The total variance is the sum of the between-group variance and within-group variance.\n",
        "\n",
        "\n",
        "\n",
        "Interpretation\n",
        "High F-value: Indicates that the between-group variance is much larger than the within-group variance, suggesting significant differences between group means.\n",
        "\n",
        "Low F-value: Suggests that any differences in means are likely due to random variation within the groups."
      ],
      "metadata": {
        "id": "MOJy4Mh3tJqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q.7. Compare the classical  approach to ANOVA with the Bayesian approach. What are the key\n",
        "differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?\n",
        "\n",
        "Answer- Alright, let's dive into the classical (frequentist) approach to ANOVA and the Bayesian approach. They both tackle the same goal‚Äîunderstanding the differences between groups‚Äîbut they do it in fundamentally different ways.\n",
        "\n",
        "Classical (Frequentist) Approach to ANOVA\n",
        "1. Uncertainty: It handles uncertainty using p-values and confidence intervals. The approach relies on long-term frequency properties of the estimators. 2. Parameter Estimation: Parameters are considered fixed but unknown. Estimates are based on sample data without incorporating prior information. 3. Hypothesis Testing: Uses p-values to determine the probability of observing the data if the null hypothesis is true. Decisions are based on significance levels (e.g., 0.05).\n",
        "\n",
        "Pros:\n",
        "\n",
        "Simplicity and widespread acceptance.\n",
        "\n",
        "Well-understood and established methods.\n",
        "\n",
        "Cons:\n",
        "\n",
        "Only uses sample data, ignoring prior information.\n",
        "\n",
        "Results can be less intuitive when dealing with small samples.\n",
        "\n",
        "Bayesian Approach to ANOVA\n",
        "1. Uncertainty: It incorporates prior distributions and updates beliefs based on the observed data using posterior distributions. This provides a more nuanced understanding of uncertainty. 2. Parameter Estimation: Parameters are treated as random variables with prior distributions. Bayes' theorem updates these priors with observed data to obtain posterior distributions. 3. Hypothesis Testing: Instead of p-values, it calculates the posterior probability of hypotheses and credible intervals. Hypotheses are evaluated in terms of probability.\n",
        "\n",
        "Pros:\n",
        "\n",
        "Incorporates prior knowledge and evidence.\n",
        "\n",
        "Provides more intuitive interpretations, especially for small sample sizes.\n",
        "\n",
        "Cons:\n",
        "\n",
        "Computationally intensive.\n",
        "\n",
        "Requires specifying priors, which can be subjective.\n",
        "\n",
        "Key Differences\n",
        "Handling Uncertainty: Frequentist uses sample data only, while Bayesian combines prior information with sample data.\n",
        "\n",
        "Parameter Estimation: Frequentist views parameters as fixed, Bayesian treats them as random variables.\n",
        "\n",
        "Hypothesis Testing: Frequentist relies on p-values, Bayesian uses posterior probabilities and credible intervals."
      ],
      "metadata": {
        "id": "MPdZCxUeuFC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q.8. Question: You have two sets of data representing the incomes of two different professions1\n",
        "V Profession A: [48, 52, 55, 60, 62]\n",
        "V Profession B: [45, 50, 55, 52, 47] Perform an F-test to determine if the variances of the two professions'\n",
        "incomes are equal. What are your conclusions based on the F-test?\n",
        "\n",
        "Task: Use Python to calculate the F-statistic and p-value for the given data.\n",
        "\n",
        "Objective: Gain experience in performing F-tests and interpreting the results in terms of variance comparison.\n",
        "\n",
        "\n",
        "Answer -\n"
      ],
      "metadata": {
        "id": "Vs1hUsgtuk1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Incomes for Profession A and B\n",
        "income_a = [48, 52, 55, 60, 62]\n",
        "income_b = [45, 50, 55, 52, 47]\n",
        "\n",
        "# Calculate variances\n",
        "var_a = np.var(income_a, ddof=1)\n",
        "var_b = np.var(income_b, ddof=1)\n",
        "\n",
        "# Calculate the F-statistic\n",
        "F = var_a / var_b\n",
        "\n",
        "# Degrees of freedom\n",
        "df1 = len(income_a) - 1\n",
        "df2 = len(income_b) - 1\n",
        "\n",
        "# Calculate the p-value\n",
        "p_value = stats.f.cdf(F, df1, df2)\n",
        "\n",
        "print(f\"F-statistic: {F}\")\n",
        "print(f\"P-value: {p_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeOEKC7uvRXp",
        "outputId": "f0814fcc-7c31-48aa-bac8-da19aa6ab9b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-statistic: 2.089171974522293\n",
            "P-value: 0.7534757004973305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Expected Output and Interpretation----------\n",
        "F-statistic: This value tells you the ratio of the two variances.\n",
        "\n",
        "P-value: If the p-value is less than the significance level (usually 0.05), you reject the null hypothesis, indicating the variances are significantly different."
      ],
      "metadata": {
        "id": "SaRvQXknv5F0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q.9. Question: Conduct a one-way ANOVA to test whether there are any statistically significant differences in\n",
        "average heights between three different regions with the following data1\n",
        "V Region A: [160, 162, 165, 158, 164'\n",
        "V Region B: [172, 175, 170, 168, 174'\n",
        "V Region C: [180, 182, 179, 185, 183'\n",
        "V Task: Write Python code to perform the one-way ANOVA and interpret the results\n",
        "V Objective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value.\n",
        "\n",
        "\n",
        "Answer-\n"
      ],
      "metadata": {
        "id": "oLJ5Bfyfv78Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Data for the three regions\n",
        "region_a = [160, 162, 165, 158, 164]\n",
        "region_b = [172, 175, 170, 168, 174]\n",
        "region_c = [180, 182, 179, 185, 183]\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_statistic, p_value = stats.f_oneway(region_a, region_b, region_c)\n",
        "\n",
        "print(f\"F-statistic: {f_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-02B_ziva4i",
        "outputId": "b721b5ab-cebc-4587-9389-fb0617680beb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-statistic: 67.87330316742101\n",
            "P-value: 2.870664187937026e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Interpretation of Results--\n",
        "\n",
        ">F-statistic: Measures the ratio of between-group variance to within-group variance. A higher value suggests greater differences between group means.\n",
        "\n",
        ">P-value: Indicates the probability of observing the data if the null hypothesis (that all group means are equal) is true.\n",
        "\n",
        "If the p-value is less than the significance level (typically 0.05), you reject the null hypothesis, indicating that there are significant differences between the average heights of the regions."
      ],
      "metadata": {
        "id": "gBbXzE0ewVGG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}